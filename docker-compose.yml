version: '3.8'

services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - config/.env
    depends_on:
      - llm-agent
      - weaviate-agent

  llm-agent:
    build:
      context: ./agents/llm-agent
      dockerfile: Dockerfile
    ports:
      - "5080:5080"
    env_file:
      - config/.env

  
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:80"
    depends_on:
      - backend

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx/default.conf:/etc/nginx/conf.d/default.conf
    depends_on:
      - frontend
      - backend
  
  weaviate:
    image: semitechnologies/weaviate:latest
    ports:
      - "8080:8080"
      - "50051:50051"
    environment:
      QUERY_DEFAULTS_LIMIT: 20
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: "./data"
      DEFAULT_VECTORIZER_MODULE: "text2vec-openai"
      ENABLE_MODULES: "text2vec-openai"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/live"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 30s
    env_file:
      - config/.env

  weaviate-agent:
    build:
      context: ./knowledge-base/weaviate-agent
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    depends_on:
      - weaviate
    env_file:
      - config/.env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/docs"]
      interval: 15s
      timeout: 5s
      retries: 5
    

