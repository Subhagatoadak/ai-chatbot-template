
# ğŸ“˜ Graph-Based Context-Aware Document Retriever

A modular, high-precision document retrieval framework using dynamic hierarchical chunking, Neo4j knowledge graphs, semantic embeddings, and hybrid search with support for FAISS, HNSWLib, and GNN-based re-ranking.

---

## âœ¨ Key Features

| Feature                              | Description                                                                                     |
|--------------------------------------|-------------------------------------------------------------------------------------------------|
| **Multiscale Chunking**              | Documents are chunked into subchunks, sentences, and phrases using adaptive token window sizes. |
| **Graph-Based Hierarchy**            | Stored in Neo4j with context-preserving parent-child relationships (document â†’ chunk â†’ phrase). |
| **Semantic Embedding**               | Embeddings generated using `sentence-transformers` (MiniLM, BERT, etc.)                         |
| **Hybrid Search**                    | Combines keyword-based filtering with semantic similarity via FAISS/HNSWlib/GNNs                |
| **Fast Similarity Retrieval**        | Support for FAISS (CPU) and HNSWLib (in-memory, ultra-fast), switchable at runtime              |
| **GNN-Based Re-Ranking**             | (Optional) Context-aware Graph Neural Network to re-rank results using document topology        |
| **Dynamic Index Update**             | Incremental updates to graph and search index as documents are added                           |
| **Customizable LLM-Free Relevance**  | Local relevance scores with HuggingFace zero-shot pipeline, no OpenAI dependency               |
| **Dockerized API with FastAPI**      | REST API for query-response and document ingestion                                              |

---

## âš™ï¸ Architecture Overview

```
PDF/Text Input
     â†“
Adaptive Chunker â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â†“                    â”‚
Embedding â†’ FAISS/HNSWlib â”‚
     â†“                    â†“
Neo4j Graph â† Chunk Metadata, Parent Links
     â†“
Query â†’ Embed + Search â†’ TopK Subchunks
     â†“
Retrieve + Ancestor Chain â†’ JSON Response
```

---

## ğŸ” Search Modes

| Mode          | Description                                                                 |
|---------------|-----------------------------------------------------------------------------|
| `faiss`       | Efficient CPU-based flat index for small to mid-sized datasets              |
| `hnswlib`     | High-speed approximate search, scalable to millions of vectors              |
| `gnn`         | [WIP] GraphSAGE/GAT-based re-ranker to refine Top-K results using hierarchy |
| `hybrid`      | Combines TF-IDF/keyword match with semantic scores for high accuracy        |

---

## ğŸ§  Algorithms and Techniques

### 1. **Multiscale Cellular Automata Chunking**
- Uses adaptive token-based segmentation.
- Scores chunks by local similarity and relevance (zero-shot classifier).
- Applies multi-pass Cellular Automata rules to select meaningful subunits.

### 2. **Neo4j Graph Store**
- Hierarchical representation of document â†’ context â†’ subchunk â†’ sentence â†’ phrase.
- Preserves traceable lineage of every result for explainable AI.

### 3. **Vector Indexing**
- `FAISS`: L2/Inner product search with index type `IndexFlatIP`.
- `HNSWLib`: Memory-mapped HNSW index with 10x+ speedup on large graphs.
- Supports GPU acceleration (if `CUDA_VISIBLE_DEVICES` is set).

### 4. **Hybrid Semantic + Keyword Search**
- TF-IDF or keyword matching boosts semantic score.
- Enables relevance tuning in domain-specific scenarios (e.g., legal, policy docs).

### 5. **Dynamic Indexing**
- Chunk additions trigger embedding + Neo4j updates.
- Vector indexes updated in-memory or persisted depending on backend.

---

## ğŸ† Why Itâ€™s Better Than Managed Vector DBs

| Benefit                         | Graph-Based Retriever                                | Managed Vector DBs                         |
|----------------------------------|------------------------------------------------------|---------------------------------------------|
| âœ… Full Graph Hierarchy          | Context traceability via parent-child relationships | âŒ Often flat vector chunks only            |
| âœ… Custom Relevance Tuning       | Plug-in scoring (LLM, ZSClassifier, TF-IDF, etc.)    | âŒ Limited to similarity + metadata filters |
| âœ… No Vendor Lock-In             | Local embeddings + storage, no cloud dependency      | âŒ Proprietary systems and pricing          |
| âœ… GNN and LLM-Compatible        | Future-proof for agent workflows and reasoning       | âŒ No support for GNNs or logic graphs      |
| âœ… Cost-Efficient for Scale      | Optimized FAISS/HNSW indexes                         | âŒ Per-query token or storage charges       |
| âœ… Incremental Indexing          | Add documents without re-ingesting everything        | âš ï¸ Often requires full re-indexing          |

---

## ğŸ”¬ Future Research Directions

- [ ] **Graph Neural Networks for Reasoning** (GraphSAGE/GAT re-rankers)
- [ ] **Contrastive Retrieval Models** fine-tuned for chunk-level relevance.
- [ ] **LLM-based Rewriting or Answer Fusion** from top retrieved chunks.
- [ ] **Agentic Traversal** of graphs for multi-hop question answering.
- [ ] **Federated Graph Indexing** across multiple domains or users.

---

## ğŸš€ Getting Started

```bash
# Install dependencies
pip install -r requirements.txt

# Start API (Neo4j must be running on bolt://localhost:7687)
uvicorn main:app --reload

# POST Query
curl -X POST http://localhost:8000/context -H "Content-Type: application/json" \
  -d '{"question": "What steps are taken in schools under POCSO?"}'
```

---

## ğŸ“‚ Folder Structure

```
.
â”œâ”€â”€ main.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ chunking.py, retriever.py, scorer.py
â”œâ”€â”€ graph/
â”‚   â””â”€â”€ neo4j_store.py, gnn_ranker.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ pocso_circular.pdf
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ¤ Contributing

We welcome contributions for:
- Custom chunking logic (e.g., syntax-based)
- Pluggable re-rankers (BGE, GNNs)
- Index sync and streaming ingestion

---

## ğŸ›¡ License

MIT License. Use it, modify it, enhance it.

---

Would you like me to:
- Split this into modular `main.py`, `retriever.py`, `scorer.py`, etc.?
- Add usage examples for each search mode (`/context?mode=faiss`, etc.)?
- Build a minimal Streamlit or Swagger interface?

Let me know how you'd like to structure the repo next ğŸ‘‡